---
authors:
- Nilaksh Das
- Haekyu Park
- Zijie J. Wang
- Fred Hohman
- Robert Firstman
- Emily Rogers
- Duen Horng (Polo) Chau
link: https://fredhohman.com/papers/bluff
tags:
- Deep Learning Visualization
- Adversarial Machine Learning
- Graph Analytics
title: 'Bluff: Interactively Deciphering Adversarial Attacks on Deep Neural Networks.'
venue: IEEE VIS
year: 2020
---
Deep neural networks (DNNs) are now commonly used in many domains. However, they are vulnerable to adversarial attacks: carefully-crafted perturbations on data inputs that can fool a model into making incorrect predictions. Despite significant research on developing DNN attack and defense techniques, people still lack an understanding of how such attacks penetrate a modelâ€™s internals. We present Bluff, an interactive system for visualizing, characterizing, and deciphering adversarial attacks on vision-based neural networks. Bluff allows people to flexibly visualize and compare the activation pathways for benign and attacked images, revealing mechanisms that adversarial attacks employ to inflict harm on a model. Bluff is open-sourced and runs in modern web browsers.
